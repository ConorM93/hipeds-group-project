from sklearn.preprocessing import PolynomialFeatures
from sklearn import linear_model
import numpy as np
import matplotlib.pyplot as plt

poly = PolynomialFeatures(degree=4)

def train():
	#X is the independent variable (bivariate in this case)
	X = np.array([
				[95.6266,  88.5283, 	73.66114855,	102.3528099, 61.48446798, 	77.87678242, 98.3375310898,  103.362762928],    # Sensor 1
				[96.4362,  81.5422, 	75.39074421,	88.72048855, 67.12712049, 	85.68245173, 94.2036747932,  81.6181063652],	# 2
				[99.5928,  88.4588, 	77.41473913, 	101.0648131, 68.34560633, 	88.45880032, 98.1494426727,  73.4158158302], 	# 3
				[100.9623, 85.6661, 	71.92746401, 	80.70628643, 68.44782829, 	61.68891191, 70.6762671471,  56.4060807228], 	# 4
				[99.6092,  87.6901,     75.93865395, 	90.69132805, 65.58152437, 	84.45987701, 79.0952682495,  53.5765767097], 	# 5
				[92.2696,  90.8263,     77.10807323, 	87.70644665, 76.69509649, 	85.88689566, 80.710375309,   55.4819941521], 	# 6
				[103.3464, 90.123,      70.36551237, 	78.25295925, 67.69138575, 	77.46789455, 82.8488588333,  105], 	# 7
				[99.7973,  86.79462671, 75.7178545, 	73.48532677, 56.45923615, 	68.51325035, 48.4491229057,  80.5222868919], 	# 8
				[100.6518, 89.64457512, 75.46025515, 	78.47784758, 64.34668303, 	67.70774126, 20.0682163239,  20.8900809288], 	# 9
				[100.5128, 73.24817181, 72.63075113, 	62.35948801, 75.92229843, 	53.35577726, 42.2381162643,  42.3403382301],	# 10
				[101.3061, 87.56742477, 68.81991625, 	70.72533369, 65.70010185, 	64.79645967, 55.6700825691,  45.6727743149], 	# 11
				[99.8668,  87.92724609, 75.42345524, 	77.27980614, 75.13723373, 	21.00865841, 21.7283010483,  21.3848352432], 	# 12
				[101.1343, 89.88581896, 81.16832972, 	56.47559166, 75.59518814, 	79.56140041, 67.691385746,   64.7433042526], 	# 13
				[97.6342,  81.66717291, 75.08407831, 	49.82298613, 71.94381952, 	73.96781445, 68.1207180023,  60.110604763], 	# 14
				[100.4147, 89.78359699, 79.30380106, 	55.12217283, 78.7027359, 	78.32247019, 56.8313241005,  56.7659020424] 	# 15
		]).T
	#print(X.shape) # (n_samples, n_features) = (n x 15)
		
	#vector is the dependent data
	vector = np.array([[0, 0.17457, 0.34914, 0.34914, 0.34914, 0.34914, 0.34914, 0.42642]]).T
	#print(vector.shape) # (n_samples, n_targets) = (n x 1)
		
	X_ = poly.fit_transform(X)

	clf = linear_model.LinearRegression()
	clf.fit(X_, vector)
	
	# Return the fitted model
	return clf


clf = train()

def estimate(measurements):
	# predict is an independent variable for which we'd like to predict the value
	#predict = np.array([[73.9351034164,  92.4699902534, 99.4169950485, 65.8227682114,  68.4110283852, 79.9007773399,  56.1321258545,  65.0131702423,  60.6094479561, 44.2130446434, 34.6246242523,  65.8391237259,  73.8983035088,  50.710272789, 57.6940774918]]) # Should be 0.40434
	predict_ = poly.fit_transform(measurements)
	#print(predict.shape)
	print("Predicting volume...")
	volume = clf.predict(predict_)
	print(volume)
	return volume

	
# ESTIMATE VOLUME
measurements = np.array([[73.9351034164,  92.4699902534, 99.4169950485, 65.8227682114,  68.4110283852, 79.9007773399,  56.1321258545,  65.0131702423,  60.6094479561, 44.2130446434, 34.6246242523,  65.8391237259,  73.8983035088,  50.710272789, 57.6940774918]]) # Should be 0.40434
estimate(measurements)

# [[0.50243809]] with 2 degrees = 21.6% error, 0.1m^3
# [[0.46493694]] with 3 degrees = 13.9419% error, 0.06m^3
# [[0.43734088]] with 4 degrees = 7.84% error, 0.03m^3
# Anymore and likely to overfit, cba to actually get enough data to check
